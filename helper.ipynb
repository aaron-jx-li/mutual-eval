{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f661826-2375-4fa8-807e-56beecc66151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a92d19-5c95-41d3-8e50-dc325c14b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted ./data/models_responses_900.jsonl → ./data/model_responses_900.json\n"
     ]
    }
   ],
   "source": [
    "def jsonl_to_json(jsonl_path, json_path):\n",
    "    data = []\n",
    "\n",
    "    # Read JSONL file (each line is a complete JSON object)\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # skip empty lines\n",
    "                data.append(json.loads(line))\n",
    "\n",
    "    # Write as a JSON array\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Converted {jsonl_path} → {json_path}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "jsonl_to_json(\"./data/models_responses_900.jsonl\", \"./data/model_responses_900.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2255808-c655-4ec6-b319-7a3af0c21442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# client = OpenAI(api_key=\"\")\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert math evaluator. Compare two model answers for the SAME math question. \"\n",
    "    \"Focus on mathematical correctness, sound reasoning, and clarity. \"\n",
    "    \"Choose which answer is better. \"\n",
    "    \"If both answers are equally good, output 'tie'. \"\n",
    "    \"If both are clearly wrong or nonsensical, output 'both_bad'. \"\n",
    "    \"Respond ONLY with one choice exactly from this set:\\n\"\n",
    "    \"model_a, model_b, tie, both_bad.\\n\"\n",
    "    \"Do NOT include any extra words or explanation.\"\n",
    ")\n",
    "\n",
    "def build_user_prompt(question, ans_a, ans_b):\n",
    "    return (\n",
    "        f\"Question:\\n{question}\\n\\n\"\n",
    "        f\"Answer A (model_a):\\n{ans_a}\\n\\n\"\n",
    "        f\"Answer B (model_b):\\n{ans_b}\\n\\n\"\n",
    "        \"Which answer is better for correctness and reasoning?\"\n",
    "    )\n",
    "    \n",
    "def run_judge(question, ans_a, ans_b):\n",
    "    \"\"\"Returns: model_a, model_b, tie, or both_bad\"\"\"\n",
    "    user_prompt = build_user_prompt(question, ans_a, ans_b)\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        max_tokens=5\n",
    "    )\n",
    "\n",
    "    label = resp.choices[0].message.content.strip()\n",
    "    if label not in {\"model_a\", \"model_b\", \"tie\", \"both_bad\"}:\n",
    "        raise ValueError(f\"LLM judge produced invalid label: {label}\")\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Main conversion: read JSONL → add judge_label → save JSONL\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def add_judge_labels(input_path, output_path):\n",
    "    out = []\n",
    "\n",
    "    # Load the whole JSON array\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for item in tqdm(data):\n",
    "        q = item[\"question\"]\n",
    "        a = item[\"answer_a\"]\n",
    "        b = item[\"answer_b\"]\n",
    "\n",
    "        label = run_judge(q, a, b)\n",
    "        item[\"judge_label\"] = label\n",
    "\n",
    "    # Write back as JSON array\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Saved judged dataset with judge_label to {output_path}\")\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# add_judge_labels(\"arena_like_data.json\", \"arena_with_labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f88796b-00f3-4f23-b6e1-738ebc0bb439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 894/894 [06:01<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved judged dataset with judge_label to ./data/arena_math_900.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_judge_labels(\"./data/arena_140k_math_filtered.json\", \"./data/arena_math_900.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7757f1a0-5f63-4398-bddc-5ad838dcc799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM judge agreement with human labels = 0.43\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/arena_math_900.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "total = 0\n",
    "num_agree = 0\n",
    "for item in data:\n",
    "    if item[\"judge_label\"] in [\"model_a\", \"model_b\"]:\n",
    "        if item[\"human_label\"] == item[\"judge_label\"]:\n",
    "            num_agree += 1\n",
    "        # else:\n",
    "        #     print(f\"human_label={item[\"human_label\"]}, judge_label={item[\"judge_label\"]}\")\n",
    "        total += 1\n",
    "agree_ratio = num_agree / total\n",
    "print(f\"LLM judge agreement with human labels = {agree_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9883b1d1-c204-43d4-a146-241c476aa420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_static_csvs(path_a, path_b, out_path=None):\n",
    "    # Load the two csvs (each has 5 models per question)\n",
    "    df_a = pd.read_csv(path_a)\n",
    "    df_b = pd.read_csv(path_b)\n",
    "\n",
    "    # (Optional sanity check) – same questions in same order?\n",
    "    if not (df_a[\"question_id\"].tolist() == df_b[\"question_id\"].tolist()):\n",
    "        print(\"Warning: question_id order differs between files. \"\n",
    "              \"We'll still combine but you may want to inspect.\")\n",
    "\n",
    "    # Tag source so we can control within-question ordering if desired\n",
    "    df_a[\"source\"] = \"A\"\n",
    "    df_b[\"source\"] = \"B\"\n",
    "\n",
    "    # Stack them\n",
    "    combined = pd.concat([df_a, df_b], ignore_index=True)\n",
    "\n",
    "    # Sort so that for each question_id we see 10 consecutive rows\n",
    "    # (first all from A, then all from B; change order if you prefer)\n",
    "    combined = (\n",
    "        combined\n",
    "        .sort_values([\"question_id\", \"source\"])  # + e.g. [\"model_name\"] if you want\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Drop the helper column if you don’t want it in the final csv\n",
    "    combined = combined.drop(columns=[\"source\"])\n",
    "\n",
    "    if out_path is not None:\n",
    "        combined.to_csv(out_path, index=False)\n",
    "        print(f\"Saved combined csv to {out_path}\")\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "201401e7-ab05-4afb-8669-45ca4ebea3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: question_id order differs between files. We'll still combine but you may want to inspect.\n",
      "Saved combined csv to ./data/static_10_models.csv\n",
      "   question_id                                           question  \\\n",
      "0     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "1     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "2     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "3     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "4     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "5     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "6     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "7     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "8     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "9     GSM-8k_1  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
      "10   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "11   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "12   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "13   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "14   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "15   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "16   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "17   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "18   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "19   GSM-8k_10  Eliza's rate per hour for the first 40 hours s...   \n",
      "\n",
      "                    model_name  \\\n",
      "0    claude-3-5-haiku-20241022   \n",
      "1             gemini-2.0-flash   \n",
      "2                  gpt-4o-mini   \n",
      "3             grok-3-mini-beta   \n",
      "4             llama-3.3-70b-it   \n",
      "5      gpt-4.1-mini-2025-04-14   \n",
      "6   claude-3-7-sonnet-20250219   \n",
      "7               gemma-3-27b-it   \n",
      "8             deepseek-v3-0324   \n",
      "9          mistral-medium-2505   \n",
      "10   claude-3-5-haiku-20241022   \n",
      "11            gemini-2.0-flash   \n",
      "12                 gpt-4o-mini   \n",
      "13            grok-3-mini-beta   \n",
      "14            llama-3.3-70b-it   \n",
      "15     gpt-4.1-mini-2025-04-14   \n",
      "16  claude-3-7-sonnet-20250219   \n",
      "17              gemma-3-27b-it   \n",
      "18            deepseek-v3-0324   \n",
      "19         mistral-medium-2505   \n",
      "\n",
      "                                       correct_answer  \\\n",
      "0   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "1   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "2   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "3   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "4   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "5   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "6   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "7   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "8   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "9   Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...   \n",
      "10  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "11  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "12  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "13  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "14  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "15  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "16  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "17  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "18  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "19  Eliza is entitled to 45 -40 = <<45-40=5>>5 hou...   \n",
      "\n",
      "                                         model_answer  judge_result level  \n",
      "0   Let's solve this step by step:\\n1. Total eggs ...             1   NaN  \n",
      "1                                                 $18             1   NaN  \n",
      "2   Janet has 16 eggs, eats 3, and uses 4 for baki...             1   NaN  \n",
      "3   Janet's ducks lay 16 eggs per day. She uses 3 ...             1   NaN  \n",
      "4                                                 $18             1   NaN  \n",
      "5   Janet makes $18 every day at the farmers' market.             1   NaN  \n",
      "6                                                 $18             1   NaN  \n",
      "7                                                  26             0   NaN  \n",
      "8                                                  18             1   NaN  \n",
      "9   Janet makes $18 every day at the farmers' market.             1   NaN  \n",
      "10                                               $475             0   NaN  \n",
      "11                                               $470             0   NaN  \n",
      "12           Eliza's earnings for this week are $460.             1   NaN  \n",
      "13  Eliza's regular hourly rate is $10 for the fir...             1   NaN  \n",
      "14  For the first 40 hours, Eliza's earnings = 40 ...             1   NaN  \n",
      "15  Eliza's earnings = (40 hours × $10) + (5 hours...             1   NaN  \n",
      "16                                               $460             1   NaN  \n",
      "17                                                460             1   NaN  \n",
      "18                                                460             1   NaN  \n",
      "19           Eliza's earnings for this week are $470.             0   NaN  \n"
     ]
    }
   ],
   "source": [
    "combined_df = combine_static_csvs(\n",
    "    \"./data/static_1.csv\",\n",
    "    \"./data/static_2.csv\",\n",
    "    out_path=\"./data/static_10_models.csv\",\n",
    ")\n",
    "\n",
    "print(combined_df.head(20))   # you should see 10 rows per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d88dfb-0ecd-471a-aea0-c2bdb5690473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load original static file (all models) and the new file (one model)\n",
    "orig = pd.read_csv(\"./data/static_1_old.csv\")\n",
    "new  = pd.read_csv(\"./data/gemini_static.csv\")\n",
    "\n",
    "# 2. Figure out which model is being updated (assumes only one in the file)\n",
    "model_to_replace = new[\"model_name\"].iloc[0]\n",
    "\n",
    "# 3. Remove old rows for this model from the original dataframe\n",
    "orig_wo_model = orig[orig[\"model_name\"] != model_to_replace].copy()\n",
    "\n",
    "# 4. Make sure columns align (optional but safe)\n",
    "new = new[orig.columns]\n",
    "\n",
    "# 5. Add the updated rows and sort\n",
    "updated = pd.concat([orig_wo_model, new], ignore_index=True)\n",
    "updated = updated.sort_values([\"question_id\", \"model_name\"]).reset_index(drop=True)\n",
    "\n",
    "# 6. Save to a new CSV (or overwrite the old one)\n",
    "updated.to_csv(\"./data/static_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90cf3b1-5c89-45b2-8d14-5cd8705c8b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
