{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f0a56f-6c57-4b4d-9593-d3b8ec2663fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoConfig,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2b5d78-f805-484b-9910-466476278566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "CACHE_DIR = \"/scratch/users/jiaxun1218\"\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-Math-7B\"  # adjust if your HF ID differs\n",
    "MAX_LEN = 1024  # prompt + answer snippet; tune as needed\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 10\n",
    "LR = 3e-4\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")\n",
    "label2id = {\n",
    "    \"model_a\": 0,\n",
    "    \"model_b\": 1,\n",
    "    \"tie\": 2,\n",
    "    \"both_bad\": 3,\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050aff47-288c-467e-bc3e-4e18b2a3dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseArenaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects a list of dicts, each with at least:\n",
    "      {\n",
    "        \"question\": str,\n",
    "        \"answer_a\": str,\n",
    "        \"answer_b\": str,\n",
    "        \"human_label\": \"model_a\" | \"model_b\" | \"tie\" | \"both_bad\"\n",
    "      }\n",
    "    \"\"\"\n",
    "    def __init__(self, data: List[Dict], tokenizer: AutoTokenizer, max_len: int = 1024):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.system_prefix = (\n",
    "            \"You are a strict math answer judge. \"\n",
    "            \"You will be given a question and an answer. \"\n",
    "            \"Evaluate the answer's correctness and reasoning quality.\\n\\n\"\n",
    "        )\n",
    "\n",
    "    def build_text(self, question: str, answer: str) -> str:\n",
    "        return (\n",
    "            self.system_prefix\n",
    "            + \"Question:\\n\"\n",
    "            + question.strip()\n",
    "            + \"\\n\\nAnswer:\\n\"\n",
    "            + answer.strip()\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        q = item[\"question\"]\n",
    "        aA = item[\"answer_a\"]\n",
    "        aB = item[\"answer_b\"]\n",
    "        lab_str = item[\"human_label\"]\n",
    "\n",
    "        # map label string -> int id\n",
    "        label_id = label2id[lab_str]\n",
    "\n",
    "        text_a = self.build_text(q, aA)\n",
    "        text_b = self.build_text(q, aB)\n",
    "\n",
    "        enc_a = self.tokenizer(\n",
    "            text_a,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc_b = self.tokenizer(\n",
    "            text_b,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids_a\": enc_a[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_a\": enc_a[\"attention_mask\"].squeeze(0),\n",
    "            \"input_ids_b\": enc_b[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask_b\": enc_b[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label_id, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 3. Collator\n",
    "# -------------------------\n",
    "\n",
    "@dataclass\n",
    "class PairwiseCollator:\n",
    "    tokenizer: AutoTokenizer\n",
    "    pad_to_multiple_of: int = 8\n",
    "\n",
    "    def __call__(self, batch: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        # We need to pad A and B separately\n",
    "        ids_a = [x[\"input_ids_a\"] for x in batch]\n",
    "        mask_a = [x[\"attention_mask_a\"] for x in batch]\n",
    "        ids_b = [x[\"input_ids_b\"] for x in batch]\n",
    "        mask_b = [x[\"attention_mask_b\"] for x in batch]\n",
    "        labels = torch.stack([x[\"labels\"] for x in batch], dim=0)\n",
    "\n",
    "        enc_a = self.tokenizer.pad(\n",
    "            {\"input_ids\": ids_a, \"attention_mask\": mask_a},\n",
    "            padding=True,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        enc_b = self.tokenizer.pad(\n",
    "            {\"input_ids\": ids_b, \"attention_mask\": mask_b},\n",
    "            padding=True,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids_a\": enc_a[\"input_ids\"],\n",
    "            \"attention_mask_a\": enc_a[\"attention_mask\"],\n",
    "            \"input_ids_b\": enc_b[\"input_ids\"],\n",
    "            \"attention_mask_b\": enc_b[\"attention_mask\"],\n",
    "            \"labels\": labels,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb4fab91-be65-4791-8654-c7bb11da40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_loss_4way(logits: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    logits: shape (batch, 4) â€“ unnormalized scores for [model_a, model_b, tie, both_bad]\n",
    "    labels: shape (batch,) with values in {0,1,2,3}\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps a causal LM with:\n",
    "      - a scalar reward head (for scores_a / scores_b)\n",
    "      - a 4-way classification head over (A,B) pairs.\n",
    "\n",
    "    LoRA is applied to the LM via PEFT; the reward_head and classifier\n",
    "    are normal nn.Linear modules.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_model: AutoModelForCausalLM):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        hidden_size = base_model.config.hidden_size\n",
    "\n",
    "        base_dtype = next(base_model.parameters()).dtype\n",
    "\n",
    "        # Reward head: scalar score from hidden vector\n",
    "        self.reward_head = nn.Linear(hidden_size, 1)\n",
    "        self.reward_head.to(dtype=base_dtype)\n",
    "\n",
    "        # 4-way classification head: takes [hA, hB] -> 4 logits\n",
    "        self.classifier = nn.Linear(2 * hidden_size, 4)\n",
    "        self.classifier.to(dtype=base_dtype)\n",
    "\n",
    "    def encode_hidden(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Return last hidden state vector for each sequence in the batch.\n",
    "        Shape: (batch, hidden_size)\n",
    "        \"\"\"\n",
    "        outputs = self.base_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        hidden_states = outputs.hidden_states[-1]  # (batch, seq, hidden)\n",
    "\n",
    "        last_indices = attention_mask.sum(dim=1) - 1\n",
    "        batch_idx = torch.arange(hidden_states.size(0), device=hidden_states.device)\n",
    "        last_hidden = hidden_states[batch_idx, last_indices]  # (batch, hidden)\n",
    "        return last_hidden\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids_a: torch.Tensor,\n",
    "        attention_mask_a: torch.Tensor,\n",
    "        input_ids_b: torch.Tensor,\n",
    "        attention_mask_b: torch.Tensor,\n",
    "        labels: torch.Tensor = None,\n",
    "    ):\n",
    "        # 1. Get hidden vectors for A and B\n",
    "        hA = self.encode_hidden(input_ids_a, attention_mask_a)  # (batch, hidden)\n",
    "        hB = self.encode_hidden(input_ids_b, attention_mask_b)  # (batch, hidden)\n",
    "\n",
    "        # 2. Scalar reward scores (for later use / diagnostics)\n",
    "        sA = self.reward_head(hA).squeeze(-1)  # (batch,)\n",
    "        sB = self.reward_head(hB).squeeze(-1)  # (batch,)\n",
    "\n",
    "        # 3. 4-way classification logits\n",
    "        pair_repr = torch.cat([hA, hB], dim=-1)  # (batch, 2*hidden)\n",
    "        logits = self.classifier(pair_repr)      # (batch, 4)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = reward_loss_4way(logits, labels)\n",
    "            return {\n",
    "                \"loss\": loss,\n",
    "                \"scores_a\": sA,\n",
    "                \"scores_b\": sB,\n",
    "                \"logits\": logits,\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"scores_a\": sA,\n",
    "                \"scores_b\": sB,\n",
    "                \"logits\": logits,\n",
    "            }\n",
    "def build_model_with_lora():\n",
    "    config = AutoConfig.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)\n",
    "    config.output_hidden_states = True  # so we can access hidden states\n",
    "\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        config=config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map={\"\": DEVICE},\n",
    "        cache_dir=CACHE_DIR,\n",
    "    )\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                        \"up_proj\", \"down_proj\", \"gate_proj\"],\n",
    "    )\n",
    "    base_model = get_peft_model(base_model, lora_config)\n",
    "    base_model.print_trainable_parameters()\n",
    "\n",
    "    rm = RewardModel(base_model)\n",
    "    rm.to(DEVICE)\n",
    "    return rm\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict_pair_label_from_logits(question, answer_a, answer_b):\n",
    "    # build inputs as usual, get model outputs ...\n",
    "    out = model(\n",
    "        input_ids_a=...,\n",
    "        attention_mask_a=...,\n",
    "        input_ids_b=...,\n",
    "        attention_mask_b=...,\n",
    "        labels=None,\n",
    "    )\n",
    "    logits = out[\"logits\"]  # (1, 4)\n",
    "    pred_id = logits.argmax(dim=-1).item()\n",
    "    pred_label = id2label[pred_id]  # {0:\"model_a\",1:\"model_b\",2:\"tie\",3:\"both_bad\"}\n",
    "    return pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c30e713e-dd12-45fe-81b7-2ea50cdd6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reward_model(\n",
    "    train_data: List[Dict],\n",
    "    val_data: List[Dict] = None,   # optional, still unused\n",
    "    test_data: List[Dict] = None,\n",
    "):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    train_ds = PairwiseArenaDataset(train_data, tokenizer, max_len=MAX_LEN)\n",
    "    collator = PairwiseCollator(tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collator,\n",
    "    )\n",
    "\n",
    "    # Build model with LoRA (now has classifier head)\n",
    "    model = build_model_with_lora()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "    # Optional test loader\n",
    "    if test_data is not None:\n",
    "        test_ds = PairwiseArenaDataset(test_data, tokenizer, max_len=MAX_LEN)\n",
    "        test_loader = DataLoader(\n",
    "            test_ds,\n",
    "            batch_size=1,          # easier for per-example stats\n",
    "            shuffle=False,\n",
    "            collate_fn=collator,\n",
    "        )\n",
    "    else:\n",
    "        test_loader = None\n",
    "\n",
    "    # --------------------------\n",
    "    # Training loop\n",
    "    # --------------------------\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "\n",
    "            out = model(\n",
    "                input_ids_a=batch[\"input_ids_a\"],\n",
    "                attention_mask_a=batch[\"attention_mask_a\"],\n",
    "                input_ids_b=batch[\"input_ids_b\"],\n",
    "                attention_mask_b=batch[\"attention_mask_b\"],\n",
    "                labels=batch[\"labels\"],              # used by CE loss\n",
    "            )\n",
    "            loss = out[\"loss\"]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (step + 1) % 50 == 0:\n",
    "                print(\n",
    "                    f\"Epoch {epoch+1} | Step {step+1} | \"\n",
    "                    f\"Train Loss {total_loss/(step+1):.4f}\"\n",
    "                )\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Avg Loss = {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # --------------------------\n",
    "        #   Test-set evaluation (4-way classification)\n",
    "        # --------------------------\n",
    "        if test_loader is not None:\n",
    "            model.eval()\n",
    "            test_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "\n",
    "            per_label_counts = Counter()\n",
    "            per_label_correct = Counter()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "\n",
    "                    out = model(\n",
    "                        input_ids_a=batch[\"input_ids_a\"],\n",
    "                        attention_mask_a=batch[\"attention_mask_a\"],\n",
    "                        input_ids_b=batch[\"input_ids_b\"],\n",
    "                        attention_mask_b=batch[\"attention_mask_b\"],\n",
    "                        labels=batch[\"labels\"],      # still compute loss on test\n",
    "                    )\n",
    "\n",
    "                    loss = out[\"loss\"]\n",
    "                    test_loss += loss.item()\n",
    "\n",
    "                    logits = out[\"logits\"]          # shape (1, 4)\n",
    "                    pred_id = logits.argmax(dim=-1).item()\n",
    "                    gold_id = batch[\"labels\"].item()\n",
    "\n",
    "                    pred_label = id2label[pred_id]\n",
    "                    gold_label = id2label[gold_id]\n",
    "\n",
    "                    total += 1\n",
    "                    per_label_counts[gold_label] += 1\n",
    "\n",
    "                    if pred_id == gold_id:\n",
    "                        correct += 1\n",
    "                        per_label_correct[gold_label] += 1\n",
    "\n",
    "            overall_acc = correct / total if total > 0 else 0.0\n",
    "            avg_test_loss = test_loss / total if total > 0 else 0.0\n",
    "\n",
    "            print(\n",
    "                f\"[Epoch {epoch+1}] Test Avg Loss = {avg_test_loss:.4f} | \"\n",
    "                f\"Overall Test Acc = {overall_acc:.4f}\"\n",
    "            )\n",
    "            print(\"  Per-label accuracy:\")\n",
    "            for lab, cnt in per_label_counts.items():\n",
    "                acc_lab = per_label_correct[lab] / cnt if cnt > 0 else 0.0\n",
    "                print(f\"    {lab:9s}: {acc_lab:.4f} (n={cnt})\")\n",
    "\n",
    "    # --------------------------\n",
    "    # Save trained LoRA RM\n",
    "    # --------------------------\n",
    "    save_dir = \"./models/qwen2_5_math7b_reward_lora_classify_bs_2\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    model.base_model.save_pretrained(save_dir)\n",
    "    torch.save(model.reward_head.state_dict(), os.path.join(save_dir, \"reward_head.pt\"))\n",
    "    print(f\"Saved LoRA RM to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b0727c-6270-4afb-b116-7ccc94e44beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_arena_json(path: str):\n",
    "    \"\"\"\n",
    "    Expects a JSON file containing a list of dicts like:\n",
    "\n",
    "    [\n",
    "      {\n",
    "        \"id\": \"...\",\n",
    "        \"question\": \"...\",\n",
    "        \"model_a\": \"...\",\n",
    "        \"model_b\": \"...\",\n",
    "        \"answer_a\": \"...\",\n",
    "        \"answer_b\": \"...\",\n",
    "        \"human_label\": \"model_a\" | \"model_b\" | \"tie\" | \"both_bad\"\n",
    "      },\n",
    "      ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Filter to examples with valid labels\n",
    "    filtered = [ex for ex in data if ex.get(\"human_label\") in label2id]\n",
    "    return filtered\n",
    "\n",
    "def split_train_val_test(data, val_ratio=0.1, test_ratio=0.1, seed=42):\n",
    "    # First train+temp vs test\n",
    "    train_val, test = train_test_split(\n",
    "        data, test_size=test_ratio, random_state=seed, shuffle=True\n",
    "    )\n",
    "    # Then split train vs val\n",
    "    val_size = val_ratio / (1.0 - test_ratio)\n",
    "    train, val = train_test_split(\n",
    "        train_val, test_size=val_size, random_state=seed, shuffle=True\n",
    "    )\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00408163-7a97-49af-95d4-c67a766759d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 894 examples\n",
      "Train: 714 Val: 90 Test: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['output_hidden_states']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67ab3ce85ae4d2e81a69b734a421d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 40,370,176 || all params: 7,655,986,688 || trainable%: 0.5273\n",
      "Epoch 1 | Step 50 | Train Loss 2.9537\n",
      "Epoch 1 | Step 100 | Train Loss 2.7170\n",
      "Epoch 1 | Step 150 | Train Loss 2.4427\n",
      "Epoch 1 | Step 200 | Train Loss 2.3119\n",
      "Epoch 1 | Step 250 | Train Loss 2.1666\n",
      "Epoch 1 | Step 300 | Train Loss 2.0797\n",
      "Epoch 1 | Step 350 | Train Loss 2.0054\n",
      "[Epoch 1] Train Avg Loss = 2.0052\n",
      "[Epoch 1] Test Avg Loss = 1.8012 | Overall Test Acc = 0.3556\n",
      "  Per-label accuracy:\n",
      "    model_a  : 1.0000 (n=32)\n",
      "    model_b  : 0.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 2 | Step 50 | Train Loss 1.4822\n",
      "Epoch 2 | Step 100 | Train Loss 1.4528\n",
      "Epoch 2 | Step 150 | Train Loss 1.4863\n",
      "Epoch 2 | Step 200 | Train Loss 1.4770\n",
      "Epoch 2 | Step 250 | Train Loss 1.4697\n",
      "Epoch 2 | Step 300 | Train Loss 1.4757\n",
      "Epoch 2 | Step 350 | Train Loss 1.4762\n",
      "[Epoch 2] Train Avg Loss = 1.4773\n",
      "[Epoch 2] Test Avg Loss = 1.4480 | Overall Test Acc = 0.2333\n",
      "  Per-label accuracy:\n",
      "    model_a  : 0.0000 (n=32)\n",
      "    model_b  : 1.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 3 | Step 50 | Train Loss 1.5470\n",
      "Epoch 3 | Step 150 | Train Loss 1.4610\n",
      "Epoch 3 | Step 200 | Train Loss 1.4531\n",
      "Epoch 3 | Step 250 | Train Loss 1.4623\n",
      "Epoch 3 | Step 300 | Train Loss 1.4571\n",
      "Epoch 3 | Step 350 | Train Loss 1.4494\n",
      "[Epoch 3] Train Avg Loss = 1.4604\n",
      "[Epoch 3] Test Avg Loss = 1.5599 | Overall Test Acc = 0.3556\n",
      "  Per-label accuracy:\n",
      "    model_a  : 1.0000 (n=32)\n",
      "    model_b  : 0.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 4 | Step 50 | Train Loss 1.4640\n",
      "Epoch 4 | Step 100 | Train Loss 1.4320\n",
      "Epoch 4 | Step 150 | Train Loss 1.4043\n",
      "Epoch 4 | Step 200 | Train Loss 1.4110\n",
      "Epoch 4 | Step 250 | Train Loss 1.4238\n",
      "Epoch 4 | Step 300 | Train Loss 2.0437\n",
      "Epoch 4 | Step 350 | Train Loss 2.3700\n",
      "[Epoch 4] Train Avg Loss = 2.3693\n",
      "[Epoch 4] Test Avg Loss = 1.8806 | Overall Test Acc = 0.2111\n",
      "  Per-label accuracy:\n",
      "    model_a  : 0.0312 (n=32)\n",
      "    model_b  : 0.0000 (n=21)\n",
      "    both_bad : 1.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 5 | Step 50 | Train Loss 1.6584\n",
      "Epoch 5 | Step 100 | Train Loss 1.8807\n",
      "Epoch 5 | Step 150 | Train Loss 1.8393\n",
      "Epoch 5 | Step 200 | Train Loss 1.7944\n",
      "Epoch 5 | Step 250 | Train Loss 1.7291\n",
      "Epoch 5 | Step 300 | Train Loss 1.6866\n",
      "Epoch 5 | Step 350 | Train Loss 1.6473\n",
      "[Epoch 5] Train Avg Loss = 1.6446\n",
      "[Epoch 5] Test Avg Loss = 1.4159 | Overall Test Acc = 0.3556\n",
      "  Per-label accuracy:\n",
      "    model_a  : 1.0000 (n=32)\n",
      "    model_b  : 0.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 6 | Step 50 | Train Loss 1.4379\n",
      "Epoch 6 | Step 100 | Train Loss 1.4348\n",
      "Epoch 6 | Step 150 | Train Loss 1.4123\n",
      "Epoch 6 | Step 200 | Train Loss 1.4111\n",
      "Epoch 6 | Step 250 | Train Loss 1.4146\n",
      "Epoch 6 | Step 300 | Train Loss 1.4112\n",
      "Epoch 6 | Step 350 | Train Loss 1.4040\n",
      "[Epoch 6] Train Avg Loss = 1.4056\n",
      "[Epoch 6] Test Avg Loss = 1.4070 | Overall Test Acc = 0.2111\n",
      "  Per-label accuracy:\n",
      "    model_a  : 0.0000 (n=32)\n",
      "    model_b  : 0.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 1.0000 (n=19)\n",
      "Epoch 7 | Step 50 | Train Loss 1.4098\n",
      "Epoch 7 | Step 100 | Train Loss 1.4124\n",
      "Epoch 7 | Step 150 | Train Loss 1.3982\n",
      "Epoch 7 | Step 200 | Train Loss 1.4007\n",
      "Epoch 7 | Step 250 | Train Loss 1.4067\n",
      "Epoch 7 | Step 300 | Train Loss 1.3967\n",
      "Epoch 7 | Step 350 | Train Loss 1.3929\n",
      "[Epoch 7] Train Avg Loss = 1.3934\n",
      "[Epoch 7] Test Avg Loss = 1.4002 | Overall Test Acc = 0.3556\n",
      "  Per-label accuracy:\n",
      "    model_a  : 1.0000 (n=32)\n",
      "    model_b  : 0.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 8 | Step 50 | Train Loss 1.2988\n",
      "Epoch 8 | Step 100 | Train Loss 1.3210\n",
      "Epoch 8 | Step 150 | Train Loss 1.3447\n",
      "Epoch 8 | Step 200 | Train Loss 1.3535\n",
      "Epoch 8 | Step 250 | Train Loss 1.3549\n",
      "Epoch 8 | Step 300 | Train Loss 1.3615\n",
      "Epoch 8 | Step 350 | Train Loss 1.3656\n",
      "[Epoch 8] Train Avg Loss = 1.3672\n",
      "[Epoch 8] Test Avg Loss = 1.3731 | Overall Test Acc = 0.3556\n",
      "  Per-label accuracy:\n",
      "    model_a  : 1.0000 (n=32)\n",
      "    model_b  : 0.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 9 | Step 50 | Train Loss 1.3911\n",
      "Epoch 9 | Step 100 | Train Loss 1.3687\n",
      "Epoch 9 | Step 150 | Train Loss 1.3787\n",
      "Epoch 9 | Step 200 | Train Loss 1.3792\n",
      "Epoch 9 | Step 250 | Train Loss 1.4229\n",
      "Epoch 9 | Step 300 | Train Loss 1.4213\n",
      "Epoch 9 | Step 350 | Train Loss 1.4212\n",
      "[Epoch 9] Train Avg Loss = 1.4194\n",
      "[Epoch 9] Test Avg Loss = 1.4012 | Overall Test Acc = 0.2333\n",
      "  Per-label accuracy:\n",
      "    model_a  : 0.0000 (n=32)\n",
      "    model_b  : 1.0000 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Epoch 10 | Step 50 | Train Loss 1.3974\n",
      "Epoch 10 | Step 100 | Train Loss 1.3990\n",
      "Epoch 10 | Step 150 | Train Loss 1.3868\n",
      "Epoch 10 | Step 200 | Train Loss 1.3914\n",
      "Epoch 10 | Step 250 | Train Loss 1.3821\n",
      "Epoch 10 | Step 300 | Train Loss 1.3807\n",
      "Epoch 10 | Step 350 | Train Loss 1.3728\n",
      "[Epoch 10] Train Avg Loss = 1.3729\n",
      "[Epoch 10] Test Avg Loss = 1.4470 | Overall Test Acc = 0.2333\n",
      "  Per-label accuracy:\n",
      "    model_a  : 0.0312 (n=32)\n",
      "    model_b  : 0.9524 (n=21)\n",
      "    both_bad : 0.0000 (n=18)\n",
      "    tie      : 0.0000 (n=19)\n",
      "Saved LoRA RM to ./models/qwen2_5_math7b_reward_lora_classify_bs_2\n"
     ]
    }
   ],
   "source": [
    "arena_data = load_arena_json(\"./data/arena_140k_math_filtered.json\")\n",
    "print(\"Loaded\", len(arena_data), \"examples\")\n",
    "\n",
    "train_data, val_data, test_data = split_train_val_test(arena_data, val_ratio=0.1, test_ratio=0.1)\n",
    "print(\"Train:\", len(train_data), \"Val:\", len(val_data), \"Test:\", len(test_data))\n",
    "# print(train_data)\n",
    "train_reward_model(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a454f-709b-49f2-b2a5-889504abf8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
